{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "002bb931-7d58-4306-88d9-d7a2b420b113",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d2982b-beb9-4836-89e5-06a698be3b58",
   "metadata": {},
   "source": [
    "Feature selection is a process where you automatically select those features in your data that contribute most to the prediction variable or output in which you are interested.\n",
    "\n",
    "Having irrelevant features in your data can decrease the accuracy of many models, especially linear algorithms like linear and logistic regression.\n",
    "\n",
    "Three benefits of performing feature selection before modeling your data are:\n",
    "\n",
    "- Reduces Overfitting: Less redundant data means less opportunity to make decisions based on noise.\n",
    "- Improves Accuracy: Less misleading data means modeling accuracy improves.\n",
    "- Reduces Training Time: Less data means that algorithms train faster.\n",
    "\n",
    "You can learn more about feature selection with scikit-learn in the article Feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667c25c9-8854-46f1-b2d4-6654c09b3edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dataidea.datasets import loadDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ab88cc-367a-4f63-b070-25789aa5c168",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadDataset('../assets/demo_cleaned.csv', \n",
    "                    inbuilt=False, file_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1509aa-98f4-462e-aa71-8fd9ec5f6312",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns=['gender'], \n",
    "                      dtype='int', drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221ee3bf-88eb-4dfc-9648-cada0271787d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>address</th>\n",
       "      <th>income</th>\n",
       "      <th>income_category</th>\n",
       "      <th>job_category</th>\n",
       "      <th>gender_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>72.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>153.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>76.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>144.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  marital_status  address  income  income_category  job_category  \\\n",
       "0   55               1       12    72.0              3.0             3   \n",
       "1   56               0       29   153.0              4.0             3   \n",
       "2   24               1        4    26.0              2.0             1   \n",
       "3   45               0        9    76.0              4.0             2   \n",
       "4   44               1       17   144.0              4.0             3   \n",
       "\n",
       "   gender_m  \n",
       "0         0  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44563b5-79d7-4764-b2e3-6dafa7086138",
   "metadata": {},
   "source": [
    "## Univariate Selection\n",
    "Statistical tests can be used to select those features that have the strongest relationship with the output variable.\n",
    "\n",
    "The scikit-learn library provides the SelectKBest class that can be used with a suite of different statistical tests to select a specific number of features.\n",
    "\n",
    "Many different statistical test scan be used with this selection method. For example the ANOVA F-value method is appropriate for numerical inputs and categorical data. This can be used via the f_classif() function. We will select the 4 best features using this method in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bd8f24-ad5d-4040-b329-4a1434654499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d92f80-f9f6-4f92-8ce3-1f0979357a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('marital_status', axis=1)\n",
    "y = data.marital_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed67177-f6d7-4d0c-ac76-81bd9dbd323e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3f805e-8810-4a3e-a35b-1981db4793be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_numeric = X_train[['age', 'income', 'address']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31694e0-9343-4873-b73c-b303ac8271cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Scores:  [3.73495613 0.40565654 0.50368697]\n",
      "Selected Features Indices:  [0 2]\n"
     ]
    }
   ],
   "source": [
    "test = SelectKBest(score_func=f_classif, k=2)\n",
    "fit = test.fit(X_train_numeric, y_train)\n",
    "scores = fit.scores_\n",
    "features = fit.transform(X_train_numeric)\n",
    "selected_indices = test.get_support(indices=True)\n",
    "\n",
    "print('Feature Scores: ', scores)\n",
    "print('Selected Features Indices: ', selected_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32719b23-5115-496f-82a8-3a4212c15e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['age', 'address']].copy()\n",
    "y = data.income\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f256d55b-780d-4590-a0fb-b5a5ecdf5eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Scores:  [0.00660376 0.0464015  2.0207761 ]\n",
      "Selected Features Indices:  [2]\n"
     ]
    }
   ],
   "source": [
    "test = SelectKBest(score_func=f_regression, k=1) # Select top 5 features, adjust k as needed\n",
    "\n",
    "# Fit the selector to the data\n",
    "fit = test.fit(X_train_numeric, y_train)\n",
    "\n",
    "# get scores\n",
    "test_scores = fit.scores_\n",
    "\n",
    "# summarize selected features\n",
    "features = fit.transform(X_train_numeric)\n",
    "\n",
    "# Get the selected feature indices\n",
    "selected_indices = fit.get_support(indices=True)\n",
    "\n",
    "print('Feature Scores: ', test_scores)\n",
    "print('Selected Features Indices: ', selected_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ad19ab-adcb-439b-b5ce-8640edcb6892",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['gender_m', 'income_category', 'job_category']].copy()\n",
    "y = data.marital_status\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa391d1-0af0-4ec0-a256-2dd3029f189f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Scores:  [0.00660376 0.0464015  2.0207761 ]\n",
      "Selected Features Indices:  [0 1]\n"
     ]
    }
   ],
   "source": [
    "test = SelectKBest(score_func = chi2, k=2)\n",
    "fit = test.fit(X_train, y_train)\n",
    "scores = fit.scores_\n",
    "features = fit.transform(X_train)\n",
    "selected_indices = fit.get_support(indices=True)\n",
    "\n",
    "print('Feature Scores: ', test_scores)\n",
    "print('Selected Features Indices: ', selected_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0298ef-12ed-4ea1-b021-d1b22c5eb7f3",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination\n",
    "The Recursive Feature Elimination (or RFE) works by recursively removing attributes and building a model on those attributes that remain.\n",
    "\n",
    "It uses the model accuracy to identify which attributes (and combination of attributes) contribute the most to predicting the target attribute.\n",
    "\n",
    "You can learn more about the RFE class in the scikit-learn documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3402545-d4e9-40da-9b46-7f8d8025fbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bfb229-f48d-407b-9090-fed93afd4951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 1\n",
      "Selected Features: [False  True False]\n",
      "Feature Ranking: [3 1 2]\n"
     ]
    }
   ],
   "source": [
    "# feature extraction\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model)\n",
    "fit = rfe.fit(X, y)\n",
    "print(\"Num Features: %d\" % fit.n_features_)\n",
    "print(\"Selected Features: %s\" % fit.support_)\n",
    "print(\"Feature Ranking: %s\" % fit.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54b853c-53d7-4f86-84fe-2f0ecb21932f",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "Bagged decision trees like Random Forest and Extra Trees can be used to estimate the importance of features.\n",
    "\n",
    "In the example below we construct a ExtraTreesClassifier classifier for the Pima Indians onset of diabetes dataset. You can learn more about the ExtraTreesClassifier class in the scikit-learn API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c573aaa5-95ef-4c34-9ba1-9056c73fc9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c86f3d2-589c-41cc-bcb9-c89f6c8424d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10237303 0.52467525 0.37295172]\n"
     ]
    }
   ],
   "source": [
    "# feature extraction\n",
    "model = ExtraTreesClassifier(n_estimators=100)\n",
    "model.fit(X, y)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db51618-e308-4d73-acc4-b4562f6cfde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88af11bd-578e-4c09-a9f4-10d75d81b434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46938775510204084"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train, y_train)\n",
    "rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cb1937-54b1-4395-a9eb-31981f187068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender_m</th>\n",
       "      <th>income_category</th>\n",
       "      <th>job_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender_m  income_category  job_category\n",
       "0         0              3.0             3\n",
       "1         1              4.0             3\n",
       "2         1              2.0             1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be7c03-938e-47b0-a6f4-17eddbbf5356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4489795918367347"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train[['income_category',\t'job_category',\t'gender_m']], y_train)\n",
    "rfc.score(X_test[['income_category',\t'job_category',\t'gender_m']], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65a16f4-6a71-41bc-b6ca-21f1007e4210",
   "metadata": {},
   "source": [
    "- `f_classif` is most applicable where the input features are continuous and the outcome is categorical.\n",
    "- `f_regression` is most applicable where the input features are continuous and the outcome is continuous.\n",
    "- `chi2` is best for when the both the input and outcome are categorical."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
